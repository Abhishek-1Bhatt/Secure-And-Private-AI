{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PATE analysis is a formal set of mechanisms that is capable of looking at the true labels without the added noise and come up with the epsilon budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how we processed predictions on one of our images without differential privacy(without adding noise to the number of\n",
    "# times that label got predicted by the different models)\n",
    "labels = np.array([9, 9, 3, 6, 9, 9, 9, 9, 8, 2])\n",
    "counts = np.bincount(labels, minlength=10)\n",
    "query_result = np.argmax(counts)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use pate analysis framework provided in the pysyft library to find the value of the minimum epsilon based on the\n",
    "# agreement that the models have(data dependent epsilon) and the maximum epsilon if the data didn't agree\n",
    "\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "# first we're gonna generate a synthetic datasest and synthetic predictions randomly which would be having the maximum \n",
    "# disagreement. This will give almost equal data dependent and data independent epsilons\n",
    "\n",
    "num_teachers, num_labels, num_examples = (100, 10, 100)\n",
    "preds = (np.random.rand(num_teachers, num_examples)*num_labels).astype(int) # fake predictions\n",
    "indices = (np.random.rand(num_examples)*num_labels).astype(int) # true answers\n",
    "\n",
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5)\n",
    "\n",
    "assert data_dep_eps < data_indep_eps\n",
    "print(\"Data Dependent Epsilon:\"+str(data_dep_eps))\n",
    "print(\"Data Independent Epsilon:\"+str(data_indep_eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above output we see that the values are almost equal\n",
    "# Now we make the models more agreeable\n",
    "preds[:, 0:50] *= 0\n",
    "\n",
    "data_dep_eps, data_indep_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5, moments=20)\n",
    "print(\"Data Dependent Epsilon:\"+str(data_dep_eps))\n",
    "print(\"Data Independent Epsilon:\"+str(data_indep_eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to get a real low value for our Data Dependent Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
