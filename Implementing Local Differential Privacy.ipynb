{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to work with more robust techniques to protect data privacy against a differencing attack. This is attained\n",
    "# with the help of adding noise to the data. Now this can be done at two levels,thus giving rise to local and global \n",
    "# differential privacy. When noise is added by the data owner before submitting the data in the database its called \n",
    "# Local Differential Privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the noise is added at the local level before sending the data to the database. Butthe question is how much noise is\n",
    "# enough? This question is dealt with the help of randomized response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Response\n",
    "Technique that is used in social sciences when surveying/asking people about any kind of unlawful or taboo behaviour to learn high level trends about the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance a sociologist tryng to learn how many people committed a certain crime. It is certain that many people will\n",
    "# not be inclined to answer this honestly. Thus, we take help of Plausible Deniability where each person is asked to answer the\n",
    "# question based on the outcome of two coin flips, which the surveyor won't be allowed to see. So, it goes like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plausible Deniability\n",
    " - Flip a coin two times\n",
    " - If the first coin flip is heads answer (yes/no) honestly\n",
    " - if the first coin flip is tails then answer according to the second coin flip,i.e., yes if heads and no if tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're are guaranteed that half of the responses will be honest responses and for the other half there's a 50-50 chance of\n",
    "# honest response.\n",
    "# Now the interesting thing is that if a person answers 'yes' then they have a certain degree plausible deniability that \n",
    "# they are only answering so, because of the coin flip. So, there is this Localized Differential Privacy for each individuals\n",
    "# data which gives them the freedom to answer more honestly. Then the researcher is able to take the aggregate of the whole \n",
    "# population and remove the added noise to get an accurate statistic.\n",
    "# For understading this process lets assume that 70% of people were actually involved in the taboo behaviour that we're\n",
    "# surveying for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the randomized responses we're guaranteed that 50% of the population will say yes with 70% probability(i.e., honestly, when the first coin flip is heads) and the other half will say yes with 50% probability(when the first coin flip is tails answer according to second coin flip which is again an equiprobable event). So, the average of the two halves , i.e., average of 50% and 70%, is going to be 60%. This value of around 60% is the value that we would have got from the survey and we could revert back to the actual value of  around 70% by understanding of the fact that the 60% is actually the average of 50% with the true percentage of people(70%) who committed the act in question. Now this knowledge is achieved without knowing whether any particular person was involved or not. This technique is quite promising, but it may come at the cost of accuracy. It is only when there is a large number of people involved in the study that the noise is effectively removed. However, if the population size is small than a lot of factors can contribute to skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all the methodology in place we can now implement Local Differential Privacy with the help of randomized responses via\n",
    "# coinflips. Lets use the mean function as our query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database generation funcitions\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_parallel_db(db,remove_index):\n",
    "    return torch.cat((db[0:remove_index], db[remove_index+1:]))\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = list()\n",
    "    \n",
    "    for i in range(len(db)):\n",
    "        parallel_dbs.append(get_parallel_db(db, i))\n",
    "    \n",
    "    return parallel_dbs\n",
    "\n",
    "def create_db_and_pdbs(num_entries):\n",
    "    \n",
    "    db = (torch.rand(num_entries) > 0.5).float()\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_pdbs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_result = torch.mean(db.float())\n",
    "true_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add noise by replacing some of the above datapoints with randomized responses as explained above. For that we first perform the coin flips for each individual in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_coin_flip = (torch.rand(len(db))>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_coin_flip = (torch.rand(len(db))>0.5).float()\n",
    "second_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now a 1 acts as a heads and 0 as tails. So, the first coin flip decides whether the person answers honestly or not. Also the 1\n",
    "# in the database is for yes and 0 for no, i.e.,those are all the honest responses. So, we can get the outcome after the first \n",
    "# coin flip by simply multiplying the database with first coin flip\n",
    "db*first_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to decide the response according to the second coin flip in places which have a zero after multiplying with the \n",
    "# first coin flip variable. That is, we want to put the outcome of second flip at (1-first_coin_flip) positions. Adding the\n",
    "# product of the database with first coin flip with the product of one minus first coin flip and second coin flip gives \n",
    "# us the augmented database which is differentially private.\n",
    "augmented_database = db.float()*first_coin_flip + (1-first_coin_flip)*second_coin_flip\n",
    "augmented_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4800)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want the database to be differentially private. So, this means that the output of our query function should give a very\n",
    "# close output to the query when done on original db\n",
    "# As discussed above the output of the query will be skewed close to 0.5 as we are doing average of 0.5 and the true result of\n",
    "# the query. This means that we need to de-skew the output\n",
    "dp_result = torch.mean(augmented_database.float())*2-0.5\n",
    "dp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can package all this functionality into a single query function\n",
    "def query(db):\n",
    "    true_result = torch.mean(db.float())\n",
    "    first_coin_flip = (torch.rand(len(db))>0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db))>0.5).float()\n",
    "    augmented_database = db.float()*first_coin_flip+(1-first_coin_flip)*second_coin_flip\n",
    "    dp_result = torch.mean(augmented_database.float())*2-0.5\n",
    "    return dp_result, true_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4800), tensor(0.5200))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise:tensor(0.5020)\n",
      "Without Noise:tensor(0.4965)\n"
     ]
    }
   ],
   "source": [
    "# Now we run the query on databases of different sizes\n",
    "db, pdbs = create_db_and_pdbs(10000) #vary size here\n",
    "private_result, true_result = query(db)\n",
    "print(\"With Noise:\"+str(private_result))\n",
    "print(\"Without Noise:\"+str(true_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our next goal is to vary the amount of noise that we're gonna add to the data. Basically we want to bias the first coin\n",
    "# flip so that there is  an increased or decreased probability of getting a 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
