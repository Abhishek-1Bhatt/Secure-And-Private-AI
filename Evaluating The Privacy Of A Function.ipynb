{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our goal is to find out the maximum amount by which a query on the database we generated in the previous\n",
    " project changes when a a value(person) is removed From the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So first we create our database and parallel database generating function\n",
    "\n",
    "import torch\n",
    "\n",
    "def create_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index], db[remove_index+1:]))\n",
    "\n",
    "def create_db_and_pdbs(num_entries):\n",
    "    \n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = list()\n",
    "    for i in range(len(db)):\n",
    "        pdbs.append(create_parallel_db(db, i))\n",
    "        \n",
    "    return db, pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_pdbs(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we write a function to make a sum query on the database\n",
    "# Note : We do not need to compute the privacy or the sensitivity of a function everytime we are in the software production \n",
    "# process as these are consistent values and are known prior\n",
    "\n",
    "def sum_query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db_result = sum_query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_query(pdb[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the output of the query changes as we remove a person from the database. That is, the output of th query is conditioned directly on the information from a lot of people in this database. The role of sensitivity here can be understood by considering that if the sensitivity of a query were zero , it will mean that the output of the query won't change regardless of who we remove from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to compute the maximum amount by which this query changes when we remove someone from the database\n",
    "\n",
    "max_distance = 0\n",
    "for pdb in pdbs:\n",
    "    pdb_result = sum_query(pdb)\n",
    "    db_distance = torch.abs(pdb_result - full_db_result) # because we're taking the difference here its also called L1 sensitivity if we take the square of distance it is L2 sensitivity\n",
    "    if db_distance  > max_distance:\n",
    "        max_distance = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can easily guess the value changes by 1 as all the data is binary and we're removing only one person , \n",
    "so either the query doesn't  change or at max changes by 1\n",
    "Also the max distance is independent of the number of entries\n",
    "Moreover, the computations we're performing here are rather useless because we know what kind of database this is, what function we're using as a query and the minimum and maximum values int the database.\n",
    "This has more been used as a tool for teaching the foundation for future concepts rather than for arriving at a specific result. The max_distance here can also be called empirical sensitivity or L1 sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the next step is to write a function that takes a query function and no. of entries in the database as arguments and \n",
    "# returns the L1 sensitivity\n",
    "\n",
    "def sensitivity(query, num_entries):\n",
    "    db = torch.rand(num_entries)>0.5\n",
    "    pdbs = list()\n",
    "    for i in range(len(db)):\n",
    "        pdbs.append(torch.cat((db[0:i], db[i+1:])))\n",
    "    full_db_result = query(db)\n",
    "    max_distance = 0\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        if db_distance > max_distance:\n",
    "            max_distance = db_distance\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(sum_query, 20) # should return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets calculate the L1 sensitivity on a query for mean of the database\n",
    "\n",
    "def mean_query(db):\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(mean_query, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sensitivity we are computing here by removing one value from the database isn' just related to removing a single value but we are supposed to remove all the information related to a person and then compute the sensitivity as will be the case when we are dealing with real world databases with multiples fields of information about a single individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we are trying to find out how much the output value from the function sensitivity is using information from each individual or is it only an aggregation of information that multiple individuals are contributing to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be apparent that its a lot easier to preserve privacy if the output of our function is actually information that multiple people are contributing to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
