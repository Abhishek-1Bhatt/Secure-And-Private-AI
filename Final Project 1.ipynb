{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek Bhatt\\.conda\\envs\\pysyft\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# use cuda if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "print(f\"Using {DEVICE} backend\")\n",
    "\n",
    "# number of teacher models.  \n",
    "# our student model accuracy will depend on this parameter\n",
    "num_teachers = 100 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline for this problem is,\n",
    "\n",
    "- Train N teacher classifier models on N(100,here) private datasets\n",
    "- Use the teacher models to label your unlabelled dataset.\n",
    "- Now you have N labels for each of our image.\n",
    "- We use the argmax query in Differentially Private manner to find which label is given by majority of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a real world implementation of the above pipeline we use MNIST data.\n",
    "\n",
    "- The training data will be divided into N parts to train the teacher models\n",
    "- The test data will be used as the student(unlabelled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnsit\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnsit\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnsit\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnsit\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnsit\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnsit\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnsit\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnsit\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnsit\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnsit\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnsit\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnsit\\MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek Bhatt\\.conda\\envs\\pysyft\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# convert to tensor and normalize \n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5],[.5])])\n",
    "# load training data\n",
    "mnsit_dataset = datasets.MNIST('./mnsit', train=True, transform=train_transform, download=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide mnist train data to num_teachers partitions\n",
    "total_size = len(mnsit_dataset)\n",
    "# length of each teacher dataset\n",
    "lengths = [int(total_size/num_teachers)]*num_teachers\n",
    "# list of all teacher dataset\n",
    "teacher_datasets = torch.utils.data.random_split(mnsit_dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create basic model, which will be used for teacher and student training both\n",
    "# It is not necessary to have same model structure for all teachers and even student model\n",
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Network,self).__init__()\n",
    "    # sequential layer : input size (batch_size, 28*28)\n",
    "    self.layer = nn.Sequential(nn.Linear(28*28, 256),\n",
    "                               # out size (batch_size, 256)\n",
    "                               nn.BatchNorm1d(256),\n",
    "                               # out size (batch_size, 256)\n",
    "                               nn.ReLU(),\n",
    "                               # out size (batch_size, 256)\n",
    "                               nn.Dropout(0.5),\n",
    "                               # out size (batch_size, 256)\n",
    "                               nn.Linear(256, 64),\n",
    "                               # out size (batch_size, 64)\n",
    "                               nn.BatchNorm1d(64),\n",
    "                               # out size (batch_size, 64)\n",
    "                               nn.ReLU(),\n",
    "                               # out size (batch_size, 64)\n",
    "                               nn.Dropout(0.5),\n",
    "                               # out size (batch_size, 64)\n",
    "                               nn.Linear(64, 10),\n",
    "                               # out size (batch_size, 10)\n",
    "                               # we will use logsoftmax instead softmax\n",
    "                               # softmax has expoential overflow issues\n",
    "                               nn.LogSoftmax(dim=1)\n",
    "                               # out size (batch_size, 10)\n",
    "                              )\n",
    "\n",
    "  def forward(self,x):\n",
    "    # x size : (batch_size, 1, 28, 28)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    # x size : (batch_size, 784)\n",
    "    x = self.layer(x)\n",
    "    # x size : (batch_size, 10)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, checkpoint_file, num_epochs=10, do_validation=False):\n",
    "  \"\"\" \n",
    "  Train a model for given dataset for given number of epochs and\n",
    "  save last epoch model checkpoint\n",
    "  \n",
    "  Parameters: \n",
    "    dataset (torch.dataset): training data\n",
    "    checkpoint_file (str): filename for saving model\n",
    "    num_epochs (int): number of training epoch\n",
    "    do_validation (bool): perform validation by dividing dataset in 90:10 ratio\n",
    "          \n",
    "  Returns: None\n",
    "  \n",
    "  \"\"\"\n",
    "  # if validation divide dataset to train and test set 90:10 ratio\n",
    "  if do_validation:\n",
    "    dataset_size = len(dataset)\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [int(0.9*dataset_size), int(0.1*dataset_size)])\n",
    "    # create train and test dataloader\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size= 32, shuffle=True)\n",
    "  else:\n",
    "    # create train dataloader using full dataset\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "  # create model and send to gpu\n",
    "  model = Network().to(DEVICE)\n",
    "  # we have used logsoftmax, so now NLLLoss\n",
    "  criterion = nn.NLLLoss()\n",
    "  # adam optimizer for training\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "  # train for num_epochs\n",
    "  for epoch in range(num_epochs):\n",
    "    # training accuracy and loss for logging\n",
    "    train_accuracy = 0\n",
    "    train_loss = 0\n",
    "    # training dataloader\n",
    "    for images, labels in trainloader:\n",
    "      # zero accumlated grads\n",
    "      optimizer.zero_grad()\n",
    "      # send images, labels to gpu\n",
    "      images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "      # run forward propagation\n",
    "      output = model.forward(images)\n",
    "      # calculate loss\n",
    "      loss = criterion(output, labels)\n",
    "      train_loss += loss.item()\n",
    "      # calculate accuracy \n",
    "      top_out, top_class = output.topk(1, dim=1)\n",
    "      success = (top_class==labels.view(*top_class.shape))\n",
    "      train_accuracy += success.sum().item()\n",
    "      # do backward propagation\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "    if do_validation:\n",
    "      # set model to evaluation\n",
    "      model.eval()\n",
    "      test_accuracy = 0\n",
    "      test_loss = 0\n",
    "      # do forward pass and calculate loss and accuracy \n",
    "      with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "          images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "          output = model.forward(images)\n",
    "          loss = criterion(output, labels)\n",
    "          test_loss += loss.item()\n",
    "          top_out, top_class = output.topk(1, dim=1) \n",
    "          success = (top_class==labels.view(*top_class.shape))\n",
    "          test_accuracy += success.sum().item()\n",
    "      # log train and test metrics\n",
    "      print(\"Epoch: {}\".format(epoch+1),\n",
    "            \"Train Loss: {:.3f}\".format(train_loss/len(trainloader)),\n",
    "            \"Train Accuracy: {:.3f}\".format(train_accuracy/len(train_set)),\n",
    "            \"Test Loss: {:.3f}\".format(test_loss/len(testloader)),\n",
    "            \"Test Accuracy: {:.3f}\".format(test_accuracy/len(test_set))\n",
    "           )\n",
    "      # set model to train\n",
    "      model.train()\n",
    "    else:\n",
    "      # log only training metrics if no validation\n",
    "      print(\"Epoch: {}\".format(epoch+1),\n",
    "            \"Train Loss: {:.3f}\".format(train_loss/len(trainloader)),\n",
    "            \"Train Accuracy: {:.3f}\".format(train_accuracy/len(dataset))\n",
    "           )\n",
    "    # save trained teacher model\n",
    "    torch.save(model.state_dict(), checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all teachers models on MNIST partition datasets\n",
    "for teacher in range(num_teachers):\n",
    "  print(\"############################### Teacher {} Model Training #############################\".format(teacher+1))\n",
    "  train_model(teacher_datasets[teacher], f\"checkpoint_teacher_{teacher+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Dataset Training \n",
    "Having trained the teacher datasets above now we use the models to predict the student dataset(mnist test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student dataset transforms \n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5],[.5])])\n",
    "# load private student dataset\n",
    "private_dataset = datasets.MNIST('./mnsit', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# mnist test dataset have 10000 examples\n",
    "private_data_size = len(private_dataset)\n",
    "\n",
    "# create dataloader for private train dataset\n",
    "private_dataloader = torch.utils.data.DataLoader(private_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model_checkpoint, dataloader):\n",
    "  \"\"\" \n",
    "  Load a trained model and make predictions\n",
    "  \n",
    "  Parameters: \n",
    "    checkpoint_file (str): filename for trained model checkpoint\n",
    "    dataloader (DataLoader): dataloader instance\n",
    "          \n",
    "  Returns: \n",
    "    preds_list (torch.Tensor): predictions for whole dataset\n",
    "  \n",
    "  \"\"\"\n",
    "  # create model \n",
    "  model = Network()\n",
    "  # load model from checkpoint\n",
    "  state_dict = torch.load(model_checkpoint)\n",
    "  model.load_state_dict(state_dict)\n",
    "  # send model to gpu\n",
    "  model = model.to(DEVICE)\n",
    "  # list for batch predictions\n",
    "  preds_list = []\n",
    "  # set model to eval mode\n",
    "  model.eval()\n",
    "  # no gradients calculation needed\n",
    "  with torch.no_grad():\n",
    "    # iterate over dataset\n",
    "    for images, labels in dataloader:\n",
    "      images = images.to(DEVICE)\n",
    "      # calculate predictions ( log of predictions)\n",
    "      preds = model.forward(images)\n",
    "      # calculate top_class\n",
    "      top_preds, top_classes = preds.topk(k=1, dim=1)\n",
    "      # append batch top_classes tensor\n",
    "      preds_list.append(top_classes.view(-1))\n",
    "  # concat all batch predictions\n",
    "  preds_list = torch.cat(preds_list).cpu()\n",
    "  # return predictions\n",
    "  return preds_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all teacher model predictions\n",
    "teacher_preds = []\n",
    "# predict for each teacher model\n",
    "for teacher in range(num_teachers):\n",
    "  teacher_preds.append(predict_model(f'checkpoint_teacher_{teacher+1}.pth', private_dataloader))\n",
    "# stack all teacher predictions\n",
    "teacher_preds = torch.stack(teacher_preds)\n",
    "print(teacher_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Teacher Predictions\n",
    "\n",
    "We have N predictions for each datapoint from our private dataset. We can aggregate N predictions using max query on bin counts for different labels.\n",
    "\n",
    "Can we train a model on those aggregated labels directly ? Yes, we can, but for increasing differenital privacy and keeping within some privacy budget, we will convert our aggreagte query to dp query. In dp query, we will add some amount of Laplacian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon budget for one aggregate dp query\n",
    "epsilon = 0.1 #@param {type:\"number\"}\n",
    "# number of labels\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have assumed, student data is unlabelled. For analysis purpose we will use real labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real targets, will not available for private dataset in real scenerio\n",
    "real_targets = private_dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Argmax Aggregation\n",
    "\n",
    "Aggregate N teacher predictions using max query on bin counts for different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher aggregation result\n",
    "teachers_argmax = list()\n",
    "for image_i in range(private_data_size):\n",
    "  # calculate bin count\n",
    "  label_counts = torch.bincount(teacher_preds[:, image_i], minlength=num_classes)\n",
    "  # take maximum bin count label\n",
    "  argmax_label = torch.argmax(label_counts)\n",
    "  teachers_argmax.append(argmax_label)\n",
    "# convert array to \n",
    "teachers_argmax = torch.tensor(teachers_argmax)\n",
    "# correct predictions\n",
    "argmax_correct = torch.sum(real_targets == teachers_argmax)\n",
    "print(\"Teachers argmax labels accuracy\", argmax_correct.item()/private_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Noisy Aggregation ( DP query)\n",
    "\n",
    "We use laplacian noise and beta will equal to **(sensitivity / epsilon )**.\n",
    "\n",
    "Sensitivity of argmax query will be one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp query results\n",
    "noisy_labels = list()\n",
    "for image_i in range(private_data_size):\n",
    "  # calculate bin count\n",
    "  label_counts = torch.bincount(teacher_preds[:, image_i], minlength=num_classes)\n",
    "  # calcuate beta for laplacian \n",
    "  beta = 1 / epsilon\n",
    "  \n",
    "  # add noise for each teacher predictions\n",
    "  for i in range(len(label_counts)):\n",
    "      label_counts[i] += np.random.laplace(0, beta, 1)[0]\n",
    "  # calculate dp label\n",
    "  noisy_label = torch.argmax(label_counts)\n",
    "  noisy_labels.append(noisy_label)\n",
    "\n",
    "noisy_labels = torch.tensor(noisy_labels)\n",
    "# accuracy for noisy or dp query results\n",
    "noisy_accuracy = torch.sum(real_targets == noisy_labels)\n",
    "\n",
    "print(\"Noisy label accuracy\", noisy_accuracy.item()/private_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATE Analysis\n",
    "\n",
    "**What is the epsilon budget, we have used ?** We can perform PATE analysis to find this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.frameworks.torch.differential_privacy import pate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory usage is getting pretty high with all predictions in PATE analysis,\n",
    "# using subset of predictions ( subset of mnist test dataset)\n",
    "# will help us understand importnace of private data size\n",
    "num_student_train = 2000 #@param {type:\"integer\"}\n",
    "teacher_preds1 = teacher_preds[:, :num_student_train].to(DEVICE)\n",
    "noisy_labels1 = noisy_labels[:num_student_train].to(DEVICE)\n",
    "teachers_argmax1 = teachers_argmax[:num_student_train].to(DEVICE)\n",
    "real_targets1 = real_targets[:num_student_train].to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Labels PATE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dependant and independant epsilon for noisy labels\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis_torch(preds=teacher_preds1, indices=noisy_labels1,\n",
    "                                                   noise_eps=epsilon, delta=1e-5, moments=10)\n",
    "print(f\"Data dependant epsilon {data_dep_eps.item()} data independent epsilon {data_ind_eps.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Argmax PATE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dependant and independant epsilon for argmax labels\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis_torch(preds=teacher_preds1, indices=teachers_argmax1,\n",
    "                                                   noise_eps=epsilon, delta=1e-5, moments=10)\n",
    "print(f\"Data dependant epsilon {data_dep_eps.item()} data independent epsilon {data_ind_eps.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Labels PATE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dependant and independant epsilon for argmax labels\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis_torch(preds=teacher_preds1, indices=real_targets1,\n",
    "                                                   noise_eps=epsilon, delta=1e-5, moments=10)\n",
    "print(f\"Data dependant epsilon {data_dep_eps.item()} data independent epsilon {data_ind_eps.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model Training\n",
    "\n",
    "Differential privacy gaurantees that any amount of postprocessing can't increase epsilon value for given dataset, which means epsilon value will be less than or equal to PATE analysis values after training deep learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save real labels\n",
    "private_real_labels = private_dataset.targets\n",
    "# replace real labels with noisy labels in private dataset\n",
    "private_dataset.targets = noisy_labels\n",
    "\n",
    "# create training and testing subset\n",
    "train_private_set = torch.utils.data.Subset(private_dataset, range(0, num_student_train))\n",
    "test_private_set = torch.utils.data.Subset(private_dataset, range(num_student_train, len(private_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train student model with noisy labels\n",
    "student_model = train_model(train_private_set, f'checkpoint_student.pth', num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test loader\n",
    "private_testloader = torch.utils.data.DataLoader(test_private_set, batch_size=32)\n",
    "# get test predictions \n",
    "test_preds = predict_model(f'checkpoint_student.pth', private_testloader)\n",
    "# calculate test predictions \n",
    "correct = torch.sum(private_real_labels[num_student_train:] == test_preds)\n",
    "# accuracy\n",
    "print(f\"student model test accuracy {correct.item()/(len(private_dataset)-num_student_train)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
